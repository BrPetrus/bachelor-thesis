\documentclass[
  digital,     %% The `digital` option enables the default options for the
               %% digital version of a document. Replace with `printed`
               %% to enable the default options for the printed version
               %% of a document.
%%  color,       %% Uncomment these lines (by removing the %% at the
%%               %% beginning) to use color in the printed version of your
%%               %% document
  oneside,     %% The `oneside` option enables one-sided typesetting,
               %% which is preferred if you are only going to submit a
               %% digital version of your thesis. Replace with `twoside`
               %% for double-sided typesetting if you are planning to
               %% also print your thesis. For double-sided typesetting,
               %% use at least 120 g/m² paper to prevent show-through.
  nosansbold,  %% The `nosansbold` option prevents the use of the
               %% sans-serif type face for bold text. Replace with
               %% `sansbold` to use sans-serif type face for bold text.
  nocolorbold, %% The `nocolorbold` option disables the usage of the
               %% blue color for bold text, instead using black. Replace
               %% with `colorbold` to use blue for bold text.
  lof,         %% The `lof` option prints the List of Figures. Replace
               %% with `nolof` to hide the List of Figures.
  lot,         %% The `lot` option prints the List of Tables. Replace
               %% with `nolot` to hide the List of Tables.
]{fithesis4}
%% The following section sets up the locales used in the thesis.
\usepackage[resetfonts]{cmap} %% We need to load the T2A font encoding
\usepackage[T1,T2A]{fontenc}  %% to use the Cyrillic fonts with Russian texts.
\usepackage[
  main=english, %% By using `czech` or `slovak` as the main locale
                %% instead of `english`, you can typeset the thesis
                %% in either Czech or Slovak, respectively.
  english, czech, slovak %% The additional keys allow
]{babel}        %% foreign texts to be typeset as follows:
%%
%%   \begin{otherlanguage}{german}  ... \end{otherlanguage}
%%   \begin{otherlanguage}{russian} ... \end{otherlanguage}
%%   \begin{otherlanguage}{czech}   ... \end{otherlanguage}
%%   \begin{otherlanguage}{slovak}  ... \end{otherlanguage}
%%
%% For non-Latin scripts, it may be necessary to load additional
%% fonts:
\usepackage{paratype}
\def\textrussian#1{{\usefont{T2A}{PTSerif-TLF}{m}{rm}#1}}
%%
%% The following section sets up the metadata of the thesis.
\thesissetup{
    date        = \the\year/\the\month/\the\day,
    university  = mu,
    faculty     = fi,
    type        = bc,
    department  = Department of Visual Computing,
    author      = Bruno Petrus,
    gender      = m,
    advisor     = {doc. RNDr. Martin Maška, Ph.D.},
    title       = {Segmentation of Membrane-Stained Cells in Image Data of Organoids},
    TeXtitle    = {Segmentation of Membrane-Stained Cells in Image Data of Organoids},
    keywords    = {keyword1, keyword2, ...},
    TeXkeywords = {keyword1, keyword2, \ldots},
    abstract    = {%
      This is the abstract of my thesis, which can

      span multiple paragraphs.
    },
    thanks      = {%
      These are the acknowledgements for my thesis, which can

      span multiple paragraphs.
    },
    bib         = bibliography.bib,
    %% Remove the following line to use the JVS 2018 faculty logo.
    facultyLogo = fithesis-fi,
}
\usepackage{makeidx}      %% The `makeidx` package contains
\makeindex                %% helper commands for index typesetting.
%% These additional packages are used within the document:
\usepackage{paralist} %% Compact list environments
\usepackage{amsmath}  %% Mathematics
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{url}      %% Hyperlinks
\usepackage{markdown} %% Lightweight markup
\usepackage{listings} %% Source code highlighting
\lstset{
  basicstyle      = \ttfamily,
  identifierstyle = \color{black},
  keywordstyle    = \color{blue},
  keywordstyle    = {[2]\color{cyan}},
  keywordstyle    = {[3]\color{olive}},
  stringstyle     = \color{teal},
  commentstyle    = \itshape\color{magenta},
  breaklines      = true,
}
\usepackage{floatrow} %% Putting captions above tables
\floatsetup[table]{capposition=top}
\usepackage[babel]{csquotes} %% Context-sensitive quotation marks

%% Specify new commands
\newcommand*{\R}{\ensuremath{\mathbb{R}}}
\newcommand*{\Z}{\ensuremath{\mathbb{Z}}}

\begin{document}
%% The \chapter* command can be used to produce unnumbered chapters:
\chapter*{Introduction}
%% Unlike \chapter, \chapter* does not update the headings and does not
%% enter the chapter to the table of contents. I we want correct
%% headings and a table of contents entry, we must add them manually:
\markright{\textsc{Introduction}}
\addcontentsline{toc}{chapter}{Introduction}

Theses are rumoured to be \enquote{the capstones of education}, so
I decided to write one of my own. If all goes well, I will soon
have a diploma under my belt. Wish me luck!

\chapter{Theory}

\section{Digital Image}

Our eyesight is arguably one of our most helpful sense for observing the world.
Researchers have developed many tools which help us study the world. I will
begin by formalizing the concept of images so that we can use mathematics
and computer science to describe them.

Essentially we can think of an image as an n-dimensional function $f(x_1, x_2,
..., x_n)$, where $x_1, x_2, .. x_n$ are coordinates inside a spatial plane,
while the function value at those coordinates specifies the magnitude or intensity
of the signal at that point. In most general terms, we can think about images as
functions of type $f:\R^n \rightarrow \R^m$, where $n$ indicates the number of
spatial dimensions and $m$ specifies the number of channels. For example, when
we are talking about two-dimensional greyscale images, $m$ is equal to 1 and $n$ is
equal to 2, while a typical coloured photograph can have more than 3 channels.

In real life, we do not necessarily work with real-valued spatial dimensions and
intensities but only have a finite number of bits. The process of
acquiring images in a finite grid and assigning intensities from a finite
range is called sampling and quantization. In essence, we create a discretized
version of the original signal, which can be represented as an array of values.
If both the coordinates and the intensity are subsets of some discrete and finite set,
we can think of them as a digital image.

\subsection{Acquiring}

\subsection{Sampling}

\subsection{Noise}

Unfortunately, we rarely acquire a perfect image without any noise. Noise
can be thought of as unwanted variations in image intensities which are not
present in the original signal. Noise in the signal may arise during multiple
steps of the process; for example, it might be a fault of an imperfect sensor,
such as when we deal with charged-coupled device cameras. There a light input is
converted into an electric signal, but such sensors only have a limited quantum
efficiency and are greatly affected by environmental factors such as 
temperature and light intensity. After the sensor, a common source of noise is
the signal's transmission. It is greatly affected by disturbances in the used
channel, such as low energy due to distance during wireless transmission or
limited baud rate of Wi-Fi and Bluetooth. While wireless interfaces have many
issues, wired alternatives come with their own limitations and liabilities such as physical damage.

\subsubsection{Typical noise in fluorescence microscopy.}

Generally, each source of noise can behave differently and in the process of restoring
images, knowing the distribution and nature of the noise is essential if we are to restore the 
image in any meaningful way. According to \parencite{hamamatsu_ccd}, there are three main sources of noise when using CCD sensors, and those are:
\begin{compactenum}
\item Photon noise
\item Dark noise
\item Read noise
\end{compactenum}

TODO

\section{Image smoothing}

\section{Edge finding}

In digital image processing, edges typically separate different regions of
interested from each other. They are very important in digital image processing
as they can be used in many workflows --- such as image segmentation and
classification --- to extract various interesting features and regions
from the image.

There is not authoritative definition of an edge, but it can be thought of as a
set of connected pixels that lie on the boundary between two regions
\parencite{gonzalez2002}. Usually there is a gradient of intensities between two
regions as can be seen on the Figure \ref{fig:edge_intensities}. To better
describe the edge, we usually use edge finding operators based on first or second
partial derivative.

\begin{figure}
    \begin{center}
        \includegraphics[width=8.3cm]{resources/inkscape/gradient.png}
    \end{center}
    \caption{Image intensities} % todo: replace
    \label{fig:edge_intensities}
\end{figure}

% todo: shape? image?


% TODO: Gradient operator, Laplace operator and Zero-crossing algorithms 

% todo some sort of beginning with motivation

\subsection{Gradient operators}

First way of calculating the edge is looking at the gradient of the image. The
gradient of an image $f(x,y)$ at position $(x, y)$ is defined as vector
\parencite{gonzalez2002}:
$$\nabla \textbf{f} = 
\begin{bmatrix}
    G_x \\
    G_y
\end{bmatrix} = 
\begin{bmatrix}
    \dfrac{\partial f}{\partial x}\\[2ex]
    \dfrac{\partial f}{\partial y}
\end{bmatrix}$$
The vector gradient represents the rate of change in the image, and it
points in the direction of the maximum rate of change. It can also be though of
as the partial derivate in the two axis. But what is often of interest is not
the bare vector, but the magnitude of the gradient, denoted as $\nabla f$.
Confusing enough this is also usually called the gradient in the literature, but
here I will differentiate it using the bold text. Formally it is defined as:
$$\nabla f = \text{mag}(\nabla \textbf{f}) = \sqrt{G_x^2 + G_y^2}$$

Now the question is how to calculate the $G_x$ and $G_y$ of some digital image.
It is not possible to calculate the partial derivates using the standard
definition from mathematical analysis, because digital images are discrete, thus
we commonly use an approximation. Even though it is very common to use something
like the Sobel filter, here a more basic Prewitt filter will suffice. The
horizontal Prewitt filter for 3x3 region looks like this:
\begin{figure}[H]
    \begin{center}
        \begin{tabular}{ |c|c|c| }
            \hline
            -1 & 0 & 1 \\
            \hline
            -1 & \underline{0} & 1 \\
            \hline
            -1 & 0 & 1 \\
            \hline
        \end{tabular}
        \begin{tabular}{ |c|c|c| }
            \hline
            -1 & -1 & -1 \\
            \hline
            0 & \underline{0} & 0 \\
            \hline
            1 & 1 & 1 \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Prewitt horizontal and vertical mask.}
\end{figure}
The underline 0 indicates the centre and the numbers specify weights in the the
neighbour of the pixel. Summing all together we arrive at the horizontal or
vertical approximation of gradient.

TODO image

\subsection{Laplacian operator}

The second common way of finding edges is using the second derivate, or more precisely
using the Laplacian. For a 2D function $f(x, y)$ the Laplacian is defines as
\parencite{gonzalez2002}:

$$\nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}$$

But in the context of digital image processing our signal is discrete, therefore
an approximation in discrete form is needed. A fairly standard way is to use the
following approximation for the partial second derivates in x direction: 
$$\frac{\partial^2 f}{\partial x^2} = f(x + 1, y) + f(x - 1, y) - 2*f(x, y)$$
and similar in the y direction:
$$\frac{\partial^2 f}{\partial y^2} = f(x, y + 1) + f(x, y - 1) - 2*f(x, y)$$
Substituting into the prior definition we get the following approximation:
$$\nabla^2 f = f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1) - 4*f(x,y)$$

TODO insert an image and description
TODO insert and examplorary image

One of the disatvatages of this approach is the sensitivity to noise. For the
demonstration purposes the effects will be shown in 1D. On the
Figure TODO the effect of noise is demonstrated. While the original signal does
not look too destroyed it is impossible to find the correct zero-crossings.
Therefore we have to help the operator by first smoothing the image. Common
approach is to first use gaussian smoothing, this is sometimes called a
Laplacian of Gaussian operator or a Mexican hat filer. The idea is that by
averaging we reduce some of the effect of the noise. The Figure TODO
demonstrates this effect.

As can be seen on the image TODO the Laplacian operator calculates 

The property of the laplacian in crossing the zero can be used to calculate the
edges inside the image. A simple possible algorithm is to go through the whole
image and check if a particular pixel at given position is positive while their
neighbours are negative. If this condition is true, we set this position to
white in the resulting image and black otherwise. This creates an TODO. Here
another useful properties of the zero-crossing algorithm can be seen. The edges
produced are thin and form closed contours.

\section{Thresholding}

\subsection{Otsu method}

TODO \parencite{otsu1979}

The Otsu thresholding method is a popular technique to determine a threshold
value betweeen two classes (ususally the foreground and the background) as such
it works well if the image has a clear bimodal distribution. The main idea of
this approach is to see the problem of finding the threshold as an
optimalization problem, where the inter-class variance of the two classes is to
be minimized. For some threshold $t$ we can define the variance as
\parencite{otsu1979}:
$$\sigma^2_W = \sigma^2_0 * \omega_0 + \sigma^2_1 * \omega_1$$  %todo: whats w?
where the weight $\omega_1$ and $\omega_2$ are the probabilities of the two classes. It
can be shown that minimizing the intra-class variance is the same as maximizing
inter-class variance \parencite{otsu1979}. This idea leads to an efficient
algorithm employed by many image processing libraries such as scikit-image.

TODO image and histogram

\subsection{Gradient threshold}

 TODO if used in local threshold

\section{Mathematical morphology}

Mathematical morphology is a tool used to extract various interesting features
from images. The tasks include edge-detecting algorithms, finding convex hulls, and filtering 
, just to name a few. In the simplest terms,
mathematical morphology looks at images as sets of numbers and modifies them using structural elements. Those can take many forms, but their shape varies based on the task we are trying
to achieve. The main use of mathematical morphology in this thesis is
to pre- and post-process image data generated by other image processing methods.
First, some basic operations on binary images are described. Note that
this area is vast and still being actively researched, and I will cover only parts which are helpful later in my
prototype.

In this branch of image processing, we look at the images through set theory
instead of looking at images as discrete-valued functions. In this context, an
image is a subset of 2-D integer space $\Z^2$, which can easily be generalized
to more dimensions. Each element of this subset $(x, y)$ represents a present
pixel at those coordinates in the image. In other words, if we look at an image
as an array of rectangular shape, then each foreground pixel's coordinates will
be included in the set representation.

\subsection{Preliminary}
Before we look at the two main operations --- erosion and dilation --- we have to
define two not-so-common operations on sets which are heavily used in
mathematical morphology.

During the following sections, we need to be able to talk about how to create a
reflection of the image around its origin, as is shown in the figure
\ref{fig:morp_refl}. Reflection is formally defined as \parencite{gonzalez2002}: 
$$\hat{B} = \{w | w=-b \text{ , for } b \in B\}$$
\begin{figure}
    \begin{center}
        \includegraphics[width=6.3cm]{resources/morph_reflection.jpg}
    \end{center}
    \caption{Morphological reflection} % todo: replace
    \label{fig:morp_refl}
\end{figure}

While manipulating images we commonly have to move parts of the image around.  In principle, a similar operation, called translation, is defined on sets. The formal definition of
moving a set $A$ by some translation vector $z$ is \parencite{gonzalez2002}:
$$(A)_z = \{c | c = a + z\text{ , for } a \in A\}$$
The operation is illustrated in Figure \ref{fig:morph_translation} where the set
$B$ is moved downwards by a vector $z$.
\begin{figure}
    \begin{center}
        \includegraphics[width=6.3cm]{resources/morph_translation.jpg}
    \end{center}
    \caption{Morphological translation} % todo: Replace
    \label{fig:morph_translation}
\end{figure}

\subsection{Dilation and Erosion}
Now it is possible to properly define two fundamental operations in the field of mathematical morphology, upon which many other operations are built. Both of
these operations include a structural element. A structural element is again a
set, but it can be used to describe how far and in which way the operation will influence the result.


\subsubsection{Dilation}
Intuitively we can think about the dilation
operator as a way to dilate spots inside an image into a bigger space. Formally it is defined
as \parencite{gonzalez2002}
$$A \oplus B = \{z | (\hat{B}_z) \cap A \neq \emptyset\}$$
where $A$ and $B$ are both sets in $\Z^2$. 

An example of dilation can be seen in the figure
\ref{fig:morph_dilation}, where two examples are shown. In the first row, we have
a square image with a side length of $d$ and a structuring element whose side length
is a fourth of the original. If we apply the dilation operation on these two
images, we get the one on the right. You can imagine taking the smaller square and
gliding it over the bigger one. If there is an overlap, we can add the centre of
the structural element to the result. 

Closer to the mathematical definition, all possible translations are applied to the structural element and if there is an overlap, we add the centre of the structural element to the resulting set.

For example, this operation can be used to join disconnected segments in an
image by choosing a large enough structural element. Its size will depend on the
particular example and does not necessarily have to be of regular size.

\begin{figure}
    \begin{center}
        \includegraphics[width=6.3cm]{resources/morph_dilation.jpg}i
    \end{center}
    \caption{Morphological dilation (Gonzalez 2002)} % todo: Replace
    \label{fig:morph_dilation}
\end{figure}

\subsubsection{Erosion}

The next essential operation is erosion. As the name suggests, we use it to erode
parts of the image which we consider unnecessary. An erosion $A \ominus B$ of
two sets $A$ and $B$, both part of $\Z^2$ space, is defined as
\parencite{gonzalez2002}: 
$$A \ominus B = \{z | (B)_z \subseteq A\}$$

Again $A$ can be thought of as an image while $B$ can be looked at as a structural
element. In contrast to the dilation operation, we are now looking if the whole
structural element fits inside $A$ as can be seen in the figure
\ref{fig:morph_erosion}. There a smaller structural element is used to cut away
parts of the bigger square.

As opposed to the dilation, we can use erosion to divide lightly connected
segments, and to erase noise and other unwanted disturbances in an image.

While mathematical morphology is a massive topic of interest to many
researchers, here I will only use the aforementioned operations. They can be
further used to define more operations such as binary opening and binary closing
and can be expanded to include grayscale images; however, I will not be using or covering
them in my thesis.

\begin{figure}
    \begin{center}
        \includegraphics[width=6.3cm]{resources/morph_erosion.jpg}
    \end{center}
    \caption{Morphological erosion (Gonzalez 2002)} % todo: Replace
    \label{fig:morph_erosion}
\end{figure}

\section{Segmentation}

\chapter{Image data}

My thesis utilized image data acquired by a fluorescence microscope of organoids
of mammary glands in mice. The original data was captured in 2011 by a group of
researchers at (\textbf{TODO}) faculty. The captured specimen is around 500
microns by 500 microns by 80 microns big with resolution around 4.3 microns per
pixel.

In fluorescence microscopy researchers are able to stain certain strucutures in
their speciment so that specific structures reemit light when the right
wavelenght is shined upon them. This allows them to create an image with density
of particular strucutres inside the specimen. In my case, the reearchers
captured the density of 6 different proteins, two of them are part of membranes
while the other 4 are mostly located inside the cell's nuclei.

Totalling at arund 576 GB, the data consists of 12 different time steps, where
each step has a size of 1920x1920x388 pixels, and 6 different channels. The data
is stored in numerous TIFF files. Every channel contains grayscale data with
16 bits per pixel. Following images in these thesis were preprocesed to enhance
the visualisation for demonstration pruposes.

\begin{figure}
    \begin{center}
        \includegraphics[width=6.3cm]{resources/C3-t006-200-scaled.jpg}
        \includegraphics[width=6.3cm]{resources/C2-t006-200-scaled.jpg}
    \end{center}
    \caption{Membraine stained channel and nucleus stained channel}
    \label{fig:data_example}
\end{figure}
In the Figure \ref{fig:data_example} a single slice of the data was taken from
two channels. They are from the same moment of time and at the same place. On
the left one of the membrane proteins is showcased while on the right a
different protein mostly from nuclei is shown.

\section{Problems with the dataset}

The size of the data and the inherent problems of fluorescence microscopy
provide the main issues in analyzing the data. Only small part of the data is
usable






\end{document}
